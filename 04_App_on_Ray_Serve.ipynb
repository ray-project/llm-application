{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a1f24-6473-4915-9d27-704ee97b9239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Any, Dict\n",
    "from operator import add\n",
    "import requests, json\n",
    "from starlette.requests import Request\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from transformers import pipeline as hf_pipeline\n",
    "\n",
    "import ray\n",
    "from ray import serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d9b6f-fb20-420f-b4df-742d2d94a6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7cbdcb-1bd8-499f-a57e-5c7e2df6f45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocalHuggingFaceEmbeddings(Embeddings):\n",
    "    def __init__(self, model_id):\n",
    "        self.model = SentenceTransformer(model_id)\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        embeddings = self.model.encode(texts)\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text: str) -> list[float]:\n",
    "        embedding = self.model.encode(text)\n",
    "        return list(map(float, embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7460f-4b99-43af-b879-24551ba32516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class VectorDBDeployment:\n",
    "    FAISS_INDEX_PATH = \"/home/ray/faiss_index\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.embeddings = LocalHuggingFaceEmbeddings(\"multi-qa-mpnet-base-dot-v1\")\n",
    "        try:\n",
    "            self.db = FAISS.load_local(self.FAISS_INDEX_PATH, self.embeddings)\n",
    "        except:\n",
    "            self.setup_db()\n",
    "            \n",
    "    def setup_db(self):\n",
    "        topics = ['The Eras Tour', '2023 XFL season']\n",
    "        loaders = [WikipediaLoader(query=topic, load_max_docs=20) for topic in topics]\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20, length_function=len,)\n",
    "        docs = add(*[loader.load() for loader in loaders])\n",
    "        print([d.metadata['title'] for d in docs])\n",
    "        chunks = text_splitter.create_documents([doc.page_content for doc in docs], metadatas=[doc.metadata for doc in docs])\n",
    "        self.db = FAISS.from_documents(chunks, self.embeddings)\n",
    "        self.db.save_local(self.FAISS_INDEX_PATH)\n",
    "        \n",
    "    def similarity_search(self, query):\n",
    "        return self.db.similarity_search(query)\n",
    "\n",
    "vecdb_deployment = VectorDBDeployment.bind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2fbc6-e653-45ce-b599-f7699ad3b2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "handle = serve.run(vecdb_deployment, name='db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d7ce9-0ce7-470c-87ee-9ba67f4eb476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(handle.similarity_search.remote(\"When did the XFL start?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bcb0c7-601a-4f79-81f9-573f42d4932f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.delete('db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81e1d2-52cf-4225-b695-6018fb59b522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625306aa-195c-455b-b935-7081c86c33ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bde69c-5642-4611-ab98-76cca879a137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StableLMPipeline(HuggingFacePipeline): \n",
    "    # Class is temporary, we are working with the authors of LangChain to make these unnecessary.\n",
    "    \n",
    "    def _call(self, prompt: str, stop: Optional[list[str]] = None) -> str:\n",
    "        response = self.pipeline(prompt, temperature=0.1, max_new_tokens=256, do_sample=True)\n",
    "        print(f\"Response is: {response}\")\n",
    "        text = response[0][\"generated_text\"][len(prompt) :]\n",
    "        return text\n",
    "\n",
    "    @classmethod\n",
    "    def from_model_id(cls, model_id: str, task: str, device: Optional[str] = None, model_kwargs: Optional[dict] = None, **kwargs: Any,):\n",
    "        pipeline = hf_pipeline(model=model_id, task=task, device=device, model_kwargs=model_kwargs, )\n",
    "        return cls(pipeline=pipeline, model_id=model_id, model_kwargs=model_kwargs, **kwargs, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af642edf-f6e4-47d9-ad62-964298cc7414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "<|SYSTEM|># StableLM Tuned (Alpha version)\n",
    "- You are a helpful, polite, fact-based agent for answering questions. \n",
    "- Your answers include enough detail for someone to follow through on your suggestions. \n",
    "<|USER|>\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "Please answer the following question using the context provided. \n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "=========\n",
    "QUESTION: {question} \n",
    "ANSWER: <|ASSISTANT|>\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd2ba8-0d80-493e-8df4-b32f315a39a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@serve.deployment(ray_actor_options={\"num_gpus\": 1.0})\n",
    "class QADeployment:\n",
    "    def __init__(self, db):\n",
    "        self.embeddings = LocalHuggingFaceEmbeddings(\"multi-qa-mpnet-base-dot-v1\")\n",
    "        self.db = db\n",
    "        self.llm = StableLMPipeline.from_model_id(\n",
    "            model_id=\"stabilityai/stablelm-tuned-alpha-7b\",\n",
    "            task=\"text-generation\",\n",
    "            model_kwargs={\"torch_dtype\": torch.float16, \"device_map\": \"auto\", 'cache_dir':'/mnt/local_storage'}\n",
    "        )\n",
    "        self.chain = load_qa_chain(llm=self.llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "\n",
    "    async def qa(self, query):\n",
    "        search_results_ref = await self.db.similarity_search.remote(query)\n",
    "        search_results = await search_results_ref\n",
    "        print(f\"Results from db are: {search_results}\")\n",
    "        result = self.chain({\"input_documents\": search_results, \"question\": query})\n",
    "        print(f\"Result is: {result}\")\n",
    "        return result[\"output_text\"]\n",
    "\n",
    "qa_deployment = QADeployment.bind(vecdb_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd70e92-ebe6-4216-9660-d68686bb465a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "handle = serve.run(qa_deployment, name='qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fd284-b04b-4d06-aa72-de1c458e8f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(handle.qa.remote(\"How many people live in San Francisco?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856f613-3825-4f81-89ee-3349b1285b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(handle.qa.remote(\"When did Taylor Swift's Eras tour start?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449cee9a-9014-45ae-8662-7f37192d9c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.delete('qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02a513-3994-4ad1-83ad-1f15752ac871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043585d-0e42-433d-9863-fbbf75d934aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class ParallelBuildVectorDBDeployment:\n",
    "    FAISS_INDEX_PATH = \"/home/ray/faiss_dist_built_index\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.embeddings = LocalHuggingFaceEmbeddings(\"multi-qa-mpnet-base-dot-v1\")\n",
    "        try:\n",
    "            self.db = FAISS.load_local(self.FAISS_INDEX_PATH, self.embeddings)\n",
    "        except:\n",
    "            self.setup_db()\n",
    "            \n",
    "    def setup_db(self):\n",
    "        topics = ['The Eras Tour', '2023 XFL season']\n",
    "        loaders = [WikipediaLoader(query=topic, load_max_docs=20) for topic in topics]\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20, length_function=len,)\n",
    "        docs = add(*[loader.load() for loader in loaders])\n",
    "        chunks = text_splitter.create_documents([doc.page_content for doc in docs], metadatas=[doc.metadata for doc in docs])\n",
    "        db_shards = 8\n",
    "        print(f\"Loading chunks into vector store ... using {db_shards} shards\")\n",
    "        shards = np.array_split(chunks, db_shards)\n",
    "        \n",
    "        @ray.remote\n",
    "        def process_shard(shard):\n",
    "            embeddings = LocalHuggingFaceEmbeddings(\"multi-qa-mpnet-base-dot-v1\")\n",
    "            result = FAISS.from_documents(shard, embeddings)\n",
    "            return result\n",
    "        \n",
    "        futures = [process_shard.remote(shards[i]) for i in range(db_shards)]\n",
    "        results = ray.get(futures)\n",
    "        self.db = results[0]\n",
    "        for i in range(1, db_shards):\n",
    "            self.db.merge_from(results[i])\n",
    "        self.db.save_local(self.FAISS_INDEX_PATH)\n",
    "        \n",
    "    def similarity_search(self, query):\n",
    "        return self.db.similarity_search(query)\n",
    "\n",
    "vecdb_deployment = ParallelBuildVectorDBDeployment.bind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f50eb9-57a2-4e4d-aa29-65f4fd8d0f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_deployment = QADeployment.bind(vecdb_deployment)\n",
    "handle = serve.run(qa_deployment, name='qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a126f-1dec-45bd-8ce5-80ece70f1280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(handle.qa.remote(\"How many people live in San Francisco?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c082ca3-c6bc-4ddb-8cde-0df617f80b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.delete('qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19c01b-e1b8-479f-aab0-2daf4beaaa6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from starlette.requests import Request\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4c2dc-c746-44f7-9636-b4cb36fdae44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@serve.deployment(ray_actor_options={\"num_gpus\": 1.0})\n",
    "class QADeployment:\n",
    "    def __init__(self, db):\n",
    "        self.embeddings = LocalHuggingFaceEmbeddings(\"multi-qa-mpnet-base-dot-v1\")\n",
    "        self.db = db\n",
    "        self.llm = StableLMPipeline.from_model_id(\n",
    "            model_id=\"stabilityai/stablelm-tuned-alpha-7b\",\n",
    "            task=\"text-generation\",\n",
    "            model_kwargs={\"torch_dtype\": torch.float16, \"device_map\": \"auto\", 'cache_dir':'/mnt/local_storage'}\n",
    "        )\n",
    "        self.chain = load_qa_chain(llm=self.llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "\n",
    "    async def qa(self, query):\n",
    "        search_results_ref = await self.db.similarity_search.remote(query)\n",
    "        search_results = await search_results_ref\n",
    "        result = self.chain({\"input_documents\": search_results, \"question\": query})\n",
    "        return result[\"output_text\"]\n",
    "    \n",
    "    async def __call__(self, request: Request) -> Dict:\n",
    "        data = await request.json()\n",
    "        data = json.loads(data)\n",
    "        output = await self.qa(data['user_input'])\n",
    "        return {\"result\": output }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e1119-3769-45b9-95d1-3cb40b9ec121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_deployment = QADeployment.bind(vecdb_deployment)\n",
    "handle = serve.run(qa_deployment, name='qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0740cde-a237-467a-80d3-5c5d5d146142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.get(handle.qa.remote(\"How many people live in San Francisco?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61c9dd-e69b-44d7-b28a-2c3c63e41f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message = \"When did Taylor Swift's Eras tour start?\"\n",
    "\n",
    "json_doc = json.dumps({ 'user_input' : message })\n",
    "\n",
    "requests.post('http://localhost:8000/', json = json_doc).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e51a68-ada4-4e1d-8ae9-428b18b71824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve.delete('qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff766ea0-83eb-48bc-9678-daa169aad8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
